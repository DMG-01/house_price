{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04db08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# House Price Prediction Model - Google Colab Notebook\n",
    "# Run this in Google Colab to train and download the model\n",
    "\n",
    "# Cell 1: Install required libraries\n",
    "!pip install scikit-learn pandas numpy joblib\n",
    "\n",
    "# Cell 2: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "from google.colab import files\n",
    "\n",
    "# Cell 3: Load dataset (using California Housing dataset as example)\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the dataset\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['PRICE'] = data.target\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Cell 4: Data Preprocessing\n",
    "# a. Handling missing values\n",
    "print(\"Checking for missing values...\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# If there were missing values, we would handle them like this:\n",
    "# df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# b. Feature selection\n",
    "X = df.drop('PRICE', axis=1)\n",
    "y = df['PRICE']\n",
    "\n",
    "print(\"\\nFeatures selected:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "# c. No categorical variables in this dataset, but if there were:\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# df['categorical_column'] = le.fit_transform(df['categorical_column'])\n",
    "\n",
    "# d. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nFeature scaling completed\")\n",
    "\n",
    "# Cell 5: Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Cell 6: Train Random Forest Regressor\n",
    "print(\"Training Random Forest Regressor...\")\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n",
    "\n",
    "# Cell 7: Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Model Evaluation Metrics ===\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': data.feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Cell 8: Save model and scaler\n",
    "# Create a dictionary with model, scaler, and feature names\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': data.feature_names\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_data, 'house_price_model.pkl')\n",
    "print(\"\\nModel saved as 'house_price_model.pkl'\")\n",
    "\n",
    "# Cell 9: Test loading the model\n",
    "loaded_model_data = joblib.load('house_price_model.pkl')\n",
    "loaded_model = loaded_model_data['model']\n",
    "loaded_scaler = loaded_model_data['scaler']\n",
    "\n",
    "# Test prediction\n",
    "test_sample = X_test[0].reshape(1, -1)\n",
    "prediction = loaded_model.predict(test_sample)\n",
    "print(f\"\\nTest prediction: ${prediction[0] * 100000:.2f}\")\n",
    "print(f\"Actual value: ${y_test.iloc[0] * 100000:.2f}\")\n",
    "print(\"\\nModel loaded successfully and ready for deployment!\")\n",
    "\n",
    "# Cell 10: Download the model file\n",
    "files.download('house_price_model.pkl')\n",
    "print(\"\\nModel file downloaded! Upload this to your project's /model/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
